{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6Xszybgowbsju8j5UoRXF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KoxF1WQ_6ykl"},"outputs":[],"source":["!pip install gradio transformers torch"]},{"cell_type":"code","source":["import gradio as gr\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# Select a model\n","model_name = \"Salesforce/codegen-2B-mono\"  # Ensure this model is available\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","# Function to generate code based on a prompt\n","def generate_code(prompt):\n","    # Adjust parameters to improve output quality\n","    inputs = tokenizer(prompt, return_tensors=\"pt\")\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens=100,       # Adjust as needed for code length\n","        temperature=0.3,          # Lower temperature for more deterministic output\n","        top_p=0.9,                # Top-p filtering to focus on more likely completions\n","        repetition_penalty=1.2,   # Penalizes repetitive phrases\n","        do_sample=True            # Enables sampling for a creative touch\n","    )\n","    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return generated_code\n","\n","# Create a Gradio interface\n","iface = gr.Interface(\n","    fn=generate_code,\n","    inputs=gr.Textbox(lines=5, label=\"Enter your prompt\"),\n","    outputs=gr.Code(language=\"python\", label=\"Generated Code\"),\n","    title=\"Python Code Generator\",\n","    description=\"Enter a description of the Python code you want to generate.\"\n",")\n","\n","# Launch the interface\n","iface.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":784},"id":"Yvq2F23KPUQl","executionInfo":{"status":"ok","timestamp":1731319582623,"user_tz":-330,"elapsed":67531,"user":{"displayName":"Shankar M","userId":"10482831461877206419"}},"outputId":"5e324609-85f2-4780-e8e2-5fc0a5fb6439"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://a5bf940d70a0deaf66.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://a5bf940d70a0deaf66.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":1}]}]}